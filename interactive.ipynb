{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77a9a8c6-bc63-4fcd-aa20-03c576e64e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217a144-7c7d-49f5-a2b3-659c9e10e9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f5df3d-d303-4c48-ab52-608a0e8217fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input for selecting folder\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "folder_options = ['models', 'models_lora', 'models_lora_large', 'models_fullfinetune', 'model_ensemble']\n",
    "folder_selector = widgets.Dropdown(options=folder_options, description='Folder:')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ff1c0f-cf37-4ae0-81be-20e2354d5fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fe77b893204646a30cbdd9c5ed878c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Folder:', options=('models', 'models_lora', 'models_lora_large', 'models_fullfinetune', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def on_folder_selection(change):\n",
    "    global selected_folder\n",
    "    selected_folder = change.new\n",
    "    print(f\"Selected folder: {selected_folder}\")\n",
    "\n",
    "folder_selector.observe(on_folder_selection, names='value')\n",
    "display(folder_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe5f32fc-e6aa-4604-b64f-359d87e70003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6876265c519d481caf4325b10cdfc629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Mode:', options=('Predict from protein + ligand pairs', 'Generate from ligand + prot…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User input for mode\n",
    "mode_options = [\n",
    "    \"Predict from protein + ligand pairs\",\n",
    "    \"Generate from ligand + protein scaffold\",\n",
    "    \"Generate from protein + ligand scaffold\"\n",
    "]\n",
    "mode_selector = widgets.RadioButtons(options=mode_options, description='Mode:')\n",
    "\n",
    "def on_mode_selection(change):\n",
    "    global selected_mode\n",
    "    selected_mode = change.new\n",
    "    print(f\"Selected mode: {selected_mode}\")\n",
    "    \n",
    "    # Update additional options based on selected mode\n",
    "    # update_additional_options()\n",
    "\n",
    "mode_selector.observe(on_mode_selection, names='value')\n",
    "display(mode_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb13faf-db08-4725-852c-a53d4304a63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080005992beb4b5bbe4017b4068ac09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='File:', options=('From Sequence', 'From CSV'), value='From Sequence')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User input for mode\n",
    "file_options = [\n",
    "    \"From Sequence\",\n",
    "    \"From CSV\"   \n",
    "]\n",
    "file_selector = widgets.RadioButtons(options=file_options, description='File:')\n",
    "\n",
    "def on_file_selection(change):\n",
    "    global selected_file\n",
    "    selected_file = change.new\n",
    "    print(f\"Selected mode: {selected_file}\")\n",
    "    \n",
    "    # Update additional options based on selected mode\n",
    "    # update_additional_options()\n",
    "\n",
    "file_selector.observe(on_file_selection, names='value')\n",
    "display(file_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd141f2-1e0d-4592-b466-edea5ada976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input for additional options based on mode\n",
    "def update_additional_options():\n",
    "    def on_predict_selection(change):\n",
    "            global selected_predict\n",
    "            selected_predict = change.new\n",
    "            print(f\"Selected properties: {selected_predict}\")\n",
    "    def on_predict_prot(change):\n",
    "            global selected_prot\n",
    "            selected_prot = change.new\n",
    "            print(f\"prot_path: {selected_prot}\")\n",
    "    def on_predict_lig(change):\n",
    "            global selected_lig\n",
    "            selected_lig = change.new\n",
    "            print(f\"prot_path: {selected_lig}\")\n",
    "\n",
    "    \n",
    "    def on_generate_scaffold(change):\n",
    "            global selected_generate_scaffold\n",
    "            selected_generate_scaffold = change.new\n",
    "            print(f\"Selected properties: {selected_generate_scaffold}\")\n",
    "    def on_generate_mask(change):\n",
    "            global selected_generate_mask\n",
    "            selected_generate_mask = change.new\n",
    "            print(f\"Selected properties: {selected_generate_mask}\")\n",
    "    def on_generate_number(change):\n",
    "            global selected_generate_number\n",
    "            selected_generate_number = change.new\n",
    "            print(f\"Selected properties: {selected_generate_number}\")\n",
    "    \n",
    "    if selected_mode == \"Predict from protein + ligand pairs\":\n",
    "        kcat_options = [\"Kcat\", \"Km\", \"Kd\", \"Ki\", \"IC50\", \"EC50\", \"Functional residue\", \"Protein + ligand embedding\", \"Protein + ligand logits\"]\n",
    "        kcat_selector = widgets.SelectMultiple(options=kcat_options, description='Properties:')\n",
    "        kcat_selector.observe(on_predict_selection, names='value')\n",
    "        protein_path = widgets.Text(description='protein_path:')\n",
    "        protein_path.observe(on_predict_prot, names='value')\n",
    "        ligand_path = widgets.Text(description='ligand_path:')\n",
    "        ligand_path.observe(on_predict_lig, names='value')\n",
    "        \n",
    "        display(kcat_selector,protein_path,ligand_path)\n",
    "        \n",
    "    elif selected_mode == \"Generate from ligand + protein scaffold\":\n",
    "        ligand_path = widgets.Text(description='ligand_path:')\n",
    "        ligand_path.observe(on_predict_lig, names='value')\n",
    "        \n",
    "        scaffold_input = widgets.Text(description='prot_Scaffold_path:')\n",
    "        scaffold_input.observe(on_generate_scaffold, names='value')\n",
    "        \n",
    "        masked_positions_input = widgets.Text(description='Masked positions:')\n",
    "        masked_positions_input.observe(on_generate_mask, names='value')\n",
    "        \n",
    "        num_examples_input = widgets.IntText(description='Number of examples:')\n",
    "        num_examples_input.observe(on_generate_number, names='value')\n",
    "\n",
    "        \n",
    "        display(ligand_path,scaffold_input, masked_positions_input, num_examples_input)\n",
    "\n",
    "    elif selected_mode == \"Generate from protein + ligand scaffold\":\n",
    "        protein_path = widgets.Text(description='protein_path:')\n",
    "        protein_path.observe(on_predict_prot, names='value')\n",
    "        \n",
    "        scaffold_input = widgets.Text(description='lig_Scaffold_path:')\n",
    "        scaffold_input.observe(on_generate_scaffold, names='value')\n",
    "        \n",
    "        masked_positions_input = widgets.Text(description='Masked positions:')\n",
    "        masked_positions_input.observe(on_generate_mask, names='value')\n",
    "        \n",
    "        num_examples_input = widgets.IntText(description='Number of examples:')\n",
    "        num_examples_input.observe(on_generate_number, names='value')\n",
    "\n",
    "        \n",
    "        display(protein_path,scaffold_input, masked_positions_input, num_examples_input)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eb1a3f1-74af-446d-8da6-7e751f257e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba144ee5e7547f98e92c23287b85d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Properties:', options=('Kcat', 'Km', 'Kd', 'Ki', 'IC50', 'EC50', 'Functional resid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc3b2f10f164af683348346e134611a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='protein_path:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6159cd69b2d4162aea9beca1964143e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='ligand_path:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "update_additional_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e917b4fb-8774-40ee-8900-4c8e488012cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1ebd0bd4864bc59776163cdc148570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Device:', options=('CPU', 'GPU'), value='CPU')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device_options = ['CPU', 'GPU']\n",
    "device_selector = widgets.RadioButtons(options=device_options, description='Device:')\n",
    "\n",
    "def on_device_selection(change):\n",
    "    global selected_device\n",
    "    selected_device = 'cuda' if change.new == 'GPU' else 'cpu'\n",
    "    print(f\"Selected device: {selected_device}\")\n",
    "\n",
    "device_selector.observe(on_device_selection, names='value')\n",
    "display(device_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c05a8f9b-9362-4cb2-917e-40734d4f175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary models and heads based on user selections.\n",
    "\n",
    "import torch\n",
    "\n",
    "# Load models based on folder and configuration\n",
    "model_files = [\n",
    "    'chem_model.pt', 'prot_model.pt', 'chem_model_lmhead.pt', 'prot_model_lmhead.pt',\n",
    "    'joint_layer3x.pt', 'kcat_head.pt', 'km_head.pt', 'ki_head.pt', 'kd_head.pt', 'IC50_head.pt',\n",
    "    'EC50_head.pt', 'site_head.pt', 'position_encoding.pt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ad1dc2-7b61-4834-bed2-23e8e35ba9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wil9fx\\AppData\\Local\\Temp\\ipykernel_20536\\202123309.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  models[f'{model_file}{i+1}'] = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded chem_model.pt1 from models/models_fold1\n",
      "Loaded prot_model.pt1 from models/models_fold1\n",
      "Loaded chem_model_lmhead.pt1 from models/models_fold1\n",
      "Loaded prot_model_lmhead.pt1 from models/models_fold1\n",
      "Loaded joint_layer3x.pt1 from models/models_fold1\n",
      "Loaded kcat_head.pt1 from models/models_fold1\n",
      "Loaded km_head.pt1 from models/models_fold1\n",
      "Loaded ki_head.pt1 from models/models_fold1\n",
      "Loaded kd_head.pt1 from models/models_fold1\n",
      "Loaded IC50_head.pt1 from models/models_fold1\n",
      "Loaded EC50_head.pt1 from models/models_fold1\n",
      "Loaded site_head.pt1 from models/models_fold1\n",
      "Loaded position_encoding.pt1 from models/models_fold1\n"
     ]
    }
   ],
   "source": [
    "# Load models based on user input\n",
    "def load_models(selected_folder, device,idx):\n",
    "    models = {}\n",
    "    for i in range(idx):\n",
    "        for model_file in model_files:\n",
    "            model_path = f'./{selected_folder}/models_fold{i+1}/{model_file}'\n",
    "            try:\n",
    "                models[f'{model_file}{i+1}'] = torch.load(model_path, map_location=device)\n",
    "                print(f\"Loaded {model_file}{i+1} from {selected_folder}/models_fold{i+1}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"{model_file}{i+1} not found in {selected_folder}/models_fold{i+1}\")\n",
    "    return models\n",
    "\n",
    "if selected_folder == 'model_ensemble':\n",
    "    models = load_models(selected_folder, selected_device,3)\n",
    "else:\n",
    "    models = load_models(selected_folder, selected_device,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "id": "97c1c615-de26-4a65-9aea-d66bfa7b2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv():\n",
    "    import pandas as pd\n",
    "    prot = list(pd.read_csv(selected_prot)['sequence'])\n",
    "    lig = list(pd.read_csv(selected_lig)['smiles'])\n",
    "    return(prot,lig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "id": "93d0ac62-284e-4351-a860-d8bba2bb1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "prot,lig = load_csv()\n",
    "print(f'number of protein is: {len(prot)}')\n",
    "print(f'number of ligand is: {len(prot)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "id": "30e50a2d-6eeb-4fed-bc6f-9e0b2ca3a92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "100%|██████████| 140/140 [00:01<00:00, 81.84it/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "# Tokenize protein and ligand sequences based on mode\n",
    "if selected_mode == \"Predict from protein + ligand pairs\":\n",
    "    model_checkpoint3 = './models/sf_tokenizer'\n",
    "    tokenizer_sf = AutoTokenizer.from_pretrained(model_checkpoint3)\n",
    "    \n",
    "    model_prot_ckpt = \"facebook/esm2_t12_35M_UR50D\"\n",
    "    tokenizer_prot = AutoTokenizer.from_pretrained(model_prot_ckpt)\n",
    "    \n",
    "    tokenizer_prot.model_max_length = 1024\n",
    "    \n",
    "    tokenizer_sf.model_max_length = 1024\n",
    "    \n",
    "\n",
    "    def tokenize_data(inputs_slf,inputs_prot):    \n",
    "        inputs_encoded_slf = tokenizer_sf(inputs_slf, padding=\"max_length\", truncation=True, max_length=tokenizer_sf.model_max_length)\n",
    "        inputs_encoded_prot = tokenizer_prot(inputs_prot, padding=\"max_length\", truncation=True, max_length=tokenizer_prot.model_max_length)\n",
    "    \n",
    "            # Prepare inputs for model_one\n",
    "        input_ids_slf = torch.tensor(inputs_encoded_slf['input_ids'])\n",
    "        attention_mask_slf = torch.tensor(inputs_encoded_slf['attention_mask'])\n",
    "        \n",
    "        \n",
    "        input_ids_prot = torch.tensor(inputs_encoded_prot['input_ids'])\n",
    "        attention_mask_prot = torch.tensor(inputs_encoded_prot['attention_mask'])\n",
    "    \n",
    "    \n",
    "        return input_ids_slf, attention_mask_slf,input_ids_prot, attention_mask_prot\n",
    "\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "    # Assuming `n` and `t3` are defined somewhere in your code\n",
    "    train_pr_1,train_sf_1 = load_csv()\n",
    "    n=1\n",
    "    for j in tqdm(range(len(train_sf_1))): \n",
    "        train_true_sf = []\n",
    "        train_attention_sf = []\n",
    "        train_true_prot = []\n",
    "        train_attention_prot = []\n",
    "        train_label = []\n",
    "    \n",
    "        for i in range(n):\n",
    "            e1, e2, e3, e4 = tokenize_data(train_sf_1[j * n + i : j * n + i + 1],train_pr_1[j * n + i : j * n + i + 1])\n",
    "            train_true_sf.append(e1.view(-1, 512*2))\n",
    "            train_attention_sf.append(e2.view(-1, 512*2))\n",
    "            train_true_prot.append(e3.view(-1, 512*2))\n",
    "            train_attention_prot.append(e4.view(-1, 512*2))\n",
    "    \n",
    "    \n",
    "        # Convert Python lists to PyTorch tensors\n",
    "        train_true_sf = torch.cat(train_true_sf)\n",
    "        train_attention_sf = torch.cat(train_attention_sf)\n",
    "        train_true_prot = torch.cat(train_true_prot)\n",
    "        train_attention_prot = torch.cat(train_attention_prot)\n",
    "    \n",
    "        combined_input = torch.cat([train_true_sf, train_attention_sf,train_true_prot, train_attention_prot], dim=1)\n",
    "    \n",
    "        # Create a PyTorch TensorDataset\n",
    "        dataset = TensorDataset(combined_input)\n",
    "    \n",
    "        # Create a PyTorch DataLoader\n",
    "        batch_size = 2\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "        # Save the PyTorch DataLoader using torch.save\n",
    "        torch.save(dataloader, f'./dataset/saved_dataset_ft{j}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "id": "6da76e93-5566-43a5-9374-d228ff8c8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pr_1,train_sf_1 = load_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "c4a5af36-ff64-4ef7-8f80-ed87017461ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_predict(number_of_batch,idx):\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    final_p_kcat = []\n",
    "    final_p_kd = []\n",
    "    final_p_ki = []\n",
    "    final_p_km = []\n",
    "    final_p_IC50 = []\n",
    "    final_p_EC50 = []\n",
    "    prot_model = models[f'prot_model.pt{idx+1}']\n",
    "    chem_model = models[f'chem_model.pt{idx+1}']\n",
    "    joint_layer = models[f'joint_layer3x.pt{idx+1}']\n",
    "    EC50_layer = models[f'EC50_head.pt{idx+1}']\n",
    "    IC50_layer = models[f'IC50_head.pt{idx+1}']\n",
    "    kcat_layer = models[f'kcat_head.pt{idx+1}']\n",
    "    kd_layer = models[f'kd_head.pt{idx+1}']\n",
    "    ki_layer = models[f'ki_head.pt{idx+1}']\n",
    "    km_layer = models[f'km_head.pt{idx+1}']\n",
    "    position_encoding = models[f'position_encoding.pt{idx+1}']\n",
    "    for param in prot_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for param in chem_model.parameters():\n",
    "        param.requires_grad = False   \n",
    "\n",
    "    for param in joint_layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in EC50_layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in IC50_layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in kcat_layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in kd_layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in ki_layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in km_layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    prot_model.to(device)\n",
    "    chem_model.to(device)\n",
    "    joint_layer.to(device)\n",
    "    position_encoding.to(device)\n",
    "    EC50_layer.to(device)\n",
    "    IC50_layer.to(device)\n",
    "    kcat_layer.to(device)\n",
    "    kd_layer.to(device)\n",
    "    ki_layer.to(device)\n",
    "    km_layer.to(device)\n",
    "\n",
    "    # Function to perform training step\n",
    "    for i in tqdm(range(number_of_batch)):\n",
    "\n",
    "        # dataset = torch.load('./llm_prot_Kcat_test/saved_dataset_ft'+f'{i}')\n",
    "        dataset = torch.load('./dataset/saved_dataset_ft'+f'{i}')\n",
    "        batch_p_kcat = []\n",
    "        batch_p_kd = []\n",
    "        batch_p_ki = []\n",
    "        batch_p_km = []\n",
    "        batch_p_IC50 = []\n",
    "        batch_p_EC50 = []\n",
    "        for batch in dataset:\n",
    "            inputs = batch\n",
    "            \n",
    "            # Prepare inputs for model\n",
    "            inputs = inputs[0].view(-1,512*8)\n",
    "            input_ids_sf = inputs[:, 512*0:512*2].view(-1,512*2).to(device).to(dtype=torch.int)\n",
    "            attention_mask_sf = inputs[:, 512*2:512*4].view(-1, 512*2).to(device).to(dtype=torch.int)\n",
    "            input_ids_prot = inputs[:, 512*4:512*6].view(-1,512*2).to(device).to(dtype=torch.int)\n",
    "            attention_mask_prot = inputs[:, 512*6:512*8].view(-1, 512*2).to(device).to(dtype=torch.int)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                sf_outputs = chem_model(input_ids_sf, attention_mask=attention_mask_sf)\n",
    "                sf_predictions = sf_outputs.last_hidden_state\n",
    "\n",
    "                student_outputs = prot_model(input_ids_prot, attention_mask=attention_mask_prot)\n",
    "                student_predictions = student_outputs.last_hidden_state\n",
    "\n",
    "\n",
    "                positions = position_encoding(torch.linspace(1,512*4,512*4,dtype=torch.int32).view(-1,512*4).to(device)).to(device)\n",
    "                combined_input = torch.cat([student_predictions,sf_predictions],dim=1).to(device)\n",
    "\n",
    "                mixture = joint_layer(combined_input+positions, attention_mask = torch.cat([attention_mask_prot,attention_mask_sf],dim=1).view(-1,1,1,512*4))\n",
    "\n",
    "                mean_mixture = torch.mean(mixture.last_hidden_state,dim=1)\n",
    "                heads = [kcat_layer,kd_layer,ki_layer,km_layer,IC50_layer,EC50_layer]\n",
    "                pred_val_kcat = heads[0](mean_mixture)\n",
    "                pred_val_kd = heads[1](mean_mixture)\n",
    "                pred_val_ki = heads[2](mean_mixture)\n",
    "                pred_val_km = heads[3](mean_mixture)\n",
    "                pred_val_IC50 = heads[4](mean_mixture)\n",
    "                pred_val_EC50 = heads[5](mean_mixture)\n",
    "\n",
    "            batch_p_kcat.append(pred_val_kcat[:,0:])\n",
    "            batch_p_kd.append(pred_val_kd[:,0:])\n",
    "            batch_p_ki.append(pred_val_ki[:,0:])\n",
    "            batch_p_km.append(pred_val_km[:,0:])\n",
    "            batch_p_IC50.append(pred_val_IC50[:,0:])\n",
    "            batch_p_EC50.append(pred_val_EC50[:,0:])\n",
    "        final_p_kcat.append(batch_p_kcat)\n",
    "        final_p_kd.append(batch_p_kd)\n",
    "        final_p_ki.append(batch_p_ki)\n",
    "        final_p_km.append(batch_p_km)\n",
    "        final_p_IC50.append(batch_p_IC50)\n",
    "        final_p_EC50.append(batch_p_EC50)\n",
    "    final_p_kcat_f = [] \n",
    "    final_p_kd_f = [] \n",
    "    final_p_ki_f = [] \n",
    "    final_p_km_f = [] \n",
    "    final_p_IC50_f = [] \n",
    "    final_p_EC50_f = [] \n",
    "    for ii in range(len(final_p_kcat)):\n",
    "        for jj in range(len(final_p_kcat[ii])):\n",
    "            final_p_kcat_f.extend(np.array(final_p_kcat[ii][jj].detach().cpu()).reshape(-1,2).tolist())\n",
    "            final_p_kd_f.extend(np.array(final_p_kd[ii][jj].detach().cpu()).reshape(-1,2).tolist())\n",
    "            final_p_ki_f.extend(np.array(final_p_ki[ii][jj].detach().cpu()).reshape(-1,2).tolist())\n",
    "            final_p_km_f.extend(np.array(final_p_km[ii][jj].detach().cpu()).reshape(-1,2).tolist())\n",
    "            final_p_IC50_f.extend(np.array(final_p_IC50[ii][jj].detach().cpu()).reshape(-1,2).tolist())\n",
    "            final_p_EC50_f.extend(np.array(final_p_EC50[ii][jj].detach().cpu()).reshape(-1,2).tolist())\n",
    "    return(final_p_kcat_f,final_p_kd_f,final_p_ki_f,final_p_km_f,final_p_IC50_f,final_p_EC50_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "e1d8e262-ae5b-4265-a667-d5521e648664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:07<00:00, 18.86it/s]\n",
      "100%|██████████| 140/140 [00:07<00:00, 18.89it/s]\n",
      "100%|██████████| 140/140 [00:07<00:00, 18.33it/s]\n"
     ]
    }
   ],
   "source": [
    "if selected_folder == 'model_ensemble':\n",
    "    final_p_kcat_f_=[]\n",
    "    final_p_kd_f_=[]\n",
    "    final_p_ki_f_ =[]\n",
    "    final_p_km_f_=[]\n",
    "    final_p_IC50_f_=[]\n",
    "    final_p_EC50_f_=[]\n",
    "    for i in range(3):\n",
    "        final_p_kcat_f,final_p_kd_f,final_p_ki_f,final_p_km_f,final_p_IC50_f,final_p_EC50_f = run_inference_predict(len(train_pr_1),i)\n",
    "        final_p_kcat_f_.append(final_p_kcat_f)\n",
    "        final_p_kd_f_.append(final_p_kd_f)\n",
    "        final_p_ki_f_.append(final_p_ki_f)\n",
    "        final_p_km_f_.append(final_p_km_f)\n",
    "        final_p_IC50_f_.append(final_p_IC50_f)\n",
    "        final_p_EC50_f_.append(final_p_EC50_f)\n",
    "else:\n",
    "    final_p_kcat_f,final_p_kd_f,final_p_ki_f,final_p_km_f,final_p_IC50_f,final_p_EC50_f = run_inference_predict(len(train_pr_1),0)\n",
    "# # final_p_kcat_f_=np.mean(np.array(final_p_kcat_f_),axis=0)\n",
    "# # final_p_kd_f_=np.mean(np.array(final_p_kd_f_),axis=0)\n",
    "# # final_p_ki_f_=np.mean(np.array(final_p_ki_f_),axis=0)\n",
    "# # final_p_km_f_=np.mean(np.array(final_p_km_f_),axis=0)\n",
    "# # final_p_IC50_f_=np.mean(np.array(final_p_IC50_f_),axis=0)\n",
    "# # final_p_EC50_f_=np.mean(np.array(final_p_EC50_f_),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ab6a8-6840-4700-ae62-61dae287aeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "4f84af6c-57e6-4f08-898f-453669dcedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_folder == 'model_ensemble':\n",
    "    final_p_kcat_fn = np.array(final_p_kcat_f_).reshape(-1,2)\n",
    "    final_p_kd_fn = np.array(final_p_kd_f_).reshape(-1,2)\n",
    "    final_p_ki_fn = np.array(final_p_ki_f_).reshape(-1,2)\n",
    "    final_p_km_fn = np.array(final_p_km_f_).reshape(-1,2)\n",
    "    final_p_IC50_fn = np.array(final_p_IC50_f_).reshape(-1,2)\n",
    "    final_p_EC50_fn = np.array(final_p_EC50_f_).reshape(-1,2)\n",
    "else:  \n",
    "    final_p_kcat_fn = np.array(final_p_kcat_f).reshape(-1,2)\n",
    "    final_p_kd_fn = np.array(final_p_kd_f).reshape(-1,2)\n",
    "    final_p_ki_fn = np.array(final_p_ki_f).reshape(-1,2)\n",
    "    final_p_km_fn = np.array(final_p_km_f).reshape(-1,2)\n",
    "    final_p_IC50_fn = np.array(final_p_IC50_f).reshape(-1,2)\n",
    "    final_p_EC50_fn = np.array(final_p_EC50_f).reshape(-1,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "b73cec39-6d6a-407c-8428-28b5fe61a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.concatenate((final_p_kcat_fn,final_p_kd_fn,final_p_ki_fn,final_p_km_fn,final_p_IC50_fn,final_p_EC50_fn),axis=0)\n",
    "df  = pd.DataFrame(out,columns=['parameter','SD'])\n",
    "df.to_csv(f'./path/to/pred{selected_folder}{itstr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ffcf35-6a7d-4915-87f1-7290fd905b67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
